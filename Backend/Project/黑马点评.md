# 黑马点评



* [黑马点评](#黑马点评)
   * [Nginx 代理](#nginx-代理)
   * [令牌拦截器](#令牌拦截器)
   * [序号生成器](#序号生成器)
   * [防穿透](#防穿透)
   * [防击穿](#防击穿)
      * [分布式锁](#分布式锁)
      * [逻辑过期](#逻辑过期)
   * [防竞争](#防竞争)
      * [乐观锁](#乐观锁)
      * [悲观锁](#悲观锁)
      * [消息队列](#消息队列)
         * [Stream](#stream)
         * [消费逻辑](#消费逻辑)
         * [业务逻辑](#业务逻辑)
   * [滚动分页：ZSet](#滚动分页zset)
      * [推送](#推送)
      * [滚动](#滚动)
   * [位置查询：GEO](#位置查询geo)
      * [插入位置](#插入位置)
      * [查找位置](#查找位置)
   * [签到记录：BitMap](#签到记录bitmap)
      * [添加](#添加)
      * [查询](#查询)
   * [访问统计：HyperLogLog](#访问统计hyperloglog)



## Nginx 代理

Nginx 是一个高性能的反向代理服务器，核心功能是**接收前端的请求并根据配置转发到后端**，不仅可以向前端屏蔽后端情况，还可以增强请求服务和响应服务，这一切都是在 `nginx_xxx.conf` 中进行设置

1. 定义后端上游服务器

    ```conf
    upstream backend {
        server 127.0.0.1:8081 max_fails=5 fail_timeout=10s weight=1;
        server 127.0.0.1:8082 max_fails=5 fail_timeout=10s weight=1;
    }
    ```

2. 映射静态资源，`/` 表示对所有 url 进行映射，`root` 指定本地的绝对路径，`index` 指定相对 root 的首页路径

    ```conf
    location / {
        root   /opt/homebrew/var/www/hm-review;
        index  index.html;
    }
    ```

3. 映射错误页，首先把所有 5xx 错误映射到错误 url，然后再把这个错误 url 映射到本地的错误页绝对路径

    ```conf
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /opt/homebrew/var/www;
    }
    ```

4. 映射业务 url，先去掉原先的前缀 `/api`，然后对请求进行增强，最后将请求路径映射到上游服务器

    ```conf
    location /api {
        # 去掉 /api 前缀
        rewrite /api(/.*) $1 break;
    
        # 增强请求
        default_type  application/json;
        keepalive_timeout   30s;  
        keepalive_requests  1000;  
        proxy_http_version 1.1;  
        proxy_pass_request_headers on;
        proxy_next_upstream error timeout;
    
        # 映射路径
        proxy_pass http://backend;
    }
    ```

5. nginx 服务：需要事先把 nginx 加入到环境变量

    ```bash
    # 开启服务
    nginx -c /path/to/nginx.conf
    
    # 重启服务
    nginx -s reload
    
    # 停止服务
    nginx -s stop
    ```



## 令牌拦截器

令牌是一种设计，即**用一个字符串来代表用户的身份，要求前端每次发起请求都把令牌放到请求头中，后端通过请求头获取到令牌，从而校验令牌而不是校验密码来认证用户**。

令牌最核心的意义在于，**既可以避免每次都让前端传 username 和 password，又可以避免频繁的访问数据库来校验身份**，只需要在第一次请求或者第一次登陆的时候创建令牌响应给前端，同时保存令牌到缓存，以后每次请求都从缓存中取出令牌来校验，这样又快又安全。

生成令牌有很多算法，本项目采取用**【UUID + 时间戳】**来确保令牌的唯一性、复杂性和随机性。

几乎所有增删改和查自己信息的操作都是需要校验令牌的，Spring 提供了**拦截器接口 HandlerInterceptor**，其中的 `preHandle` 方法就是专门负责**对所有进入 Controller 的请求进行预分析和预处理**，在这里可以按以下步骤执行：

1. 从请求头中获取令牌
2. 如果令牌不在缓存之中，返回 false，表示拦截并拒绝请求
3. 如果令牌在缓存之中，就提取缓存中令牌对应的用户信息，保存到 ThreadLocal 中，从而在整个请求期间，任何地方都可以获取到用户信息，而不需要将用户信息作为传参一层一层传递
4. 刷新令牌在缓存中的有效期，返回 true，表示放行并允许请求

至于什么时候把令牌添加到缓存之中，就是在用户登陆的时候，如果 username 和 password 正确，就创建令牌作为 key，用户信息作为 value 放到缓存之中。

然而，需要注意的是，如果是查别人的信息或者访问公开公共的资源，比如**访问 Swagger，访问 index.html，访问 /login 等**，这个时候就不应该对请求进行用户认证。而拦截器类本身是不会起作用的，是需要在 WebMvcConfigurer 的实现类中进行手动注册，其中就提供了 `addPathPatterns` 和 `excludePathPatterns` 两种方法来灵活地配置拦截路径和放行路径。

```java
// 这里扩展了功能，将 Token 存在与否判断转化为 ThreadLocal 存在与否的判断，本质是一样的，因为只有 Token 存在才会设置 ThreadLocal
// ThreadLocalUserUtil 封装了对常量 ThreadLocal 进行 save、get、delete 的三种静态方法
@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
    // 1. 获取令牌，没有就直接放行，则 ThreadLocal 为 null
    String token = request.getHeader("authorization");
    if (StrUtil.isBlank(token)) {
        return true;
    }

    // 2. 获取用户，没有就直接放行，则 ThreadLocal 为 null
    String key = LOGIN_USER_KEY + token;
    String userJson = redisTemplate.opsForValue().get(key);
    if (StrUtil.isBlank(userJson)) {
        return true;
    }

    // 3. 将用户保存在 ThreadLocal
    UserDTO user = JSONUtil.toBean(userJson, UserDTO.class);
    ThreadLocalUserUtil.saveUser(user);

    // 4. 刷新有效期
    redisTemplate.expire(key, LOGIN_USER_TTL, TimeUnit.MINUTES);
    return true;
}
```



## 序号生成器

在单机数据库里，自增主键很好用，但是在分布式情况下，多个实例同时写入，很难保证自增 ID 的全局唯一性，即使能做到，也容易引发竞争，数据库成为性能瓶颈。

所以分布式场景下，**可以利用 Redis 的 INCR 原子操作来保证在高并发下返回的序列号唯一且递增**。但是如果只用 INCR，数值会无限增大，最终可能溢出。可以利用当前时间戳作为序号的前 32 位，后 32 位拼接 Redis 存储的自增序号，这样在一秒内最多能生成 42 亿个不重复 ID，完全不用担心 ID 冲突！

```java
// 分布式全局唯一 ID 生成器
@Component
public class RedisId {

    @Autowired
    private StringRedisTemplate redisTemplate;

    public long nextId(String prefix) {
        // 1. 生成时间戳
        Long now = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC);
        long timestamp = now - BEGIN_TIMESTAMP;

        // 2. 生成序列号
        String date = LocalDate.now().toString().replace("-", ":");
        String key = "icr:" + prefix + ":" + date;
        Long increment = redisTemplate.opsForValue().increment(key);

        // 3. 拼接 ID
        return (timestamp << COUNT_BITS) | increment;
    }
}
```



## 防穿透

缓存穿透指的是：**如果一个数据既不在缓存，也不在数据库，那么请求将永远绕过缓存，打到数据库，拿到空值，从而对数据库造成很大压力。**

造成这个现象的主要原因是传统设计只把存在的数据放到缓存，导致请求无论如何都不可能打到缓存上。因此解决的办法也很简单，只需要**在数据库查到数据不存在后，给 Redis 写入一个特殊值**，比如 "" 或者 "not exist" 作为 value 存在缓存中，**在这之后查到缓存是这些值的时候，就可以意识到这个数据在数据库肯定是不存在的，立马返回空即可**。

```java
// 1. 查缓存
String dataJson = redisTemplate.opsForValue().get(dataKey);

// 2. 存在则直接返回
if (StrUtil.isNotBlank(dataJson)) {
    log.debug("缓存查到店铺：{}", id);
    return JSONUtil.toBean(dataJson, clazz);
}

// 3. 空值也直接返回
if ("".equals(dataJson)) {
    log.debug("缓存告知店铺不存在：{}", id);
    return null;
}
```



## 防击穿

缓存击穿指的是：**如果热点 Key 在某一时刻过期、被替换或者被删除，那么请求将会瞬间全部打到数据库，从而导致数据库崩溃。**

### 分布式锁

造成数据库崩溃的本质是所有请求都能打到数据库，如果我们把数据库当作共享资源，那么**利用互斥锁就可以保证同一时刻只有一个请求能够到达数据库，其他请求阻塞一小段时间后重新回到缓存，看看那个请求是否完成了组织安排的任务，从数据库中查到了数据并写到了缓存**。

```java
public <R, ID> R queryByLogicalExp(String dataKeyPrefix, String name, ID id, Class<R> clazz, Function<ID, R> dbSelect, Long exp, TimeUnit timeUnit)   {
    String dataKey = dataKeyPrefix + id;
    String lockName = name + ":" + id;

    // 1. 查缓存
    String dataJson = redisTemplate.opsForValue().get(dataKey);

    // 2. 空值则直接返回，防止缓存穿透
    if ("".equals(dataJson)) {
        log.debug("缓存告知店铺不存在：{}", id);
        return null;
    }

    // 3. 不存在则直接返回，没有配置热键
    if (StrUtil.isBlank(dataJson)) {
        log.debug("热点 Key 丢失：{}", dataKey);
        return null;
    }

    // 4. 获取缓存对象
    RedisDataWithExp redisData = JSONUtil.toBean(dataJson, RedisDataWithExp.class);
    R r = JSONUtil.toBean((JSONObject) redisData.getData(), clazz);

    // 5. 没过期则直接返回
    if (redisData.getExpireTime().isAfter(LocalDateTime.now())) {
        log.debug("缓存查到未过期店铺：{}", id);
        return r;
    }

    // 6. 过期则获取锁来重建，防止缓存击穿
    RedisLock redisLock = new RedisLock(lockName, redisTemplate);
    boolean isLock = redisLock.tryLock(LOCK_TTL);

    // 7. 异步重建
    if (isLock) {
        asyncRebuildThread.submit(() -> {
            try {
                // 7.1 查数据库
                R db_r = dbSelect.apply(id);

                // 7.2 写缓存
                if (db_r == null) {
                    this.setData(dataKey, "", CACHE_NULL_TTL, timeUnit);
                    log.debug("数据库告知店铺不存在：{}", id);
                } else {
                    this.setDataWithExp(dataKey, db_r, exp, timeUnit);
                    log.debug("数据库查到店铺：{}", id);
                }
            } finally {
                // 7.3 释放锁
                redisLock.unlock();
            }
        });
    }
    log.debug("缓存查到已过期店铺：{}", id);
    return r;
}
```

虽然 Java 本身就已经提供了 `ReentrantLock` 和 `synchronized` 机制来实现单机多线程级别的互斥访问，可是如果涉及到多进程或者多机器，那么锁将完全失效。这时候就可以利用第三方的 Redis 的来提供分布式锁，本质就是**利用锁的 key 是否存在来表示是否加锁**，但是需要确保三个效果：

- **不会死锁**：给锁设置过期时间，这样哪怕加锁的线程挂了，锁也可以被自动释放
- **不会误解**：为每个加锁线程构造一个唯一标识，作为锁的 value，只有自己的标识和 value 相等的才可以解锁
- **可以重入**：不仅要查是否加锁，还要查加锁人是不是自己，如果是则刷新锁的有效期

然而还需要注意的是，需要用到 Lua 脚本来处理一些原子操作：

- **鉴别锁和续期锁**：否则很有可能在续约前锁被释放了
- **鉴别锁和解除锁**：否则很有可能解除别人在空窗期加的锁

```java
public <R, ID> R queryByLock(String dataKeyPrefix, String name, ID id, Class<R> clazz, Function<ID, R> dbSelect, Long exp, TimeUnit timeUnit)   {
    String dataKey = dataKeyPrefix + id;
    String lockName = name + ":" + id;

    // 1. 查缓存
    String dataJson = redisTemplate.opsForValue().get(dataKey);

    // 2. 存在则直接返回
    if (StrUtil.isNotBlank(dataJson)) {
        log.debug("缓存查到店铺：{}", id);
        return JSONUtil.toBean(dataJson, clazz);
    }

    // 3. 空值则直接返回，防止缓存穿透
    if ("".equals(dataJson)) {
        log.debug("缓存告知店铺不存在：{}", id);
        return null;
    }

    // 4. 获取锁来查数据库，防止缓存击穿
    RedisLock redisLock = new RedisLock(lockName, redisTemplate);
    boolean isLock = redisLock.tryLock(LOCK_TTL);

    // 5. 没有获得锁则递归查询
    if (!isLock) {
        ThreadUtil.sleep(200);
        return queryByLock(dataKeyPrefix, name, id, clazz, dbSelect, exp, timeUnit);
    }

    // 6. 获得锁的则查数据库
    else {
        try {
            // 6.1 获取锁则查数据库
            R r = dbSelect.apply(id);

            // 6.2 获取锁的写缓存
            if (r == null) {
                this.setData(dataKey, "", CACHE_NULL_TTL, timeUnit);
                log.debug("数据库告知不存在：{}", id);
            } else {
                this.setData(dataKey, r, exp, timeUnit);
                log.debug("数据库查到并写入缓存：{}", id);
            }
            return r;
        } catch (Exception e) {
            throw new RuntimeException(e);
        } finally {
            // 6.3 获取锁的释放锁
            redisLock.unlock();
        }
    }
}
```

### 逻辑过期

上述分布式锁有一个弊端，那就是只有一个请求能够很快地给出结果，其他请求可能不得不等待，而且如果那个拿到锁的线程挂了，所有请求都要至少等待锁的过期时间，这对用户来说是难以接受的。

逻辑过期是另一种方法，数据不设置过期时间，而是设置到期时间，只要当前时间超过了到期时间，就认为数据无效，但永远不会把数据从缓存中移除，所以需要事先给缓存预热，把热点 Key 存到缓存中。

在发现热点 Key 逻辑过期的时候，也是派出一个线程去查数据、写缓存和更新到期时间，只不过这个线程也是异步创建一个线程去查，与其他线程一样，不会原地阻塞等待，而是直接返回查到的过期结果，牺牲一定的数据一致性来换取用户的体验性。

```java
public <R, ID> R queryByLogicalExp(String dataKeyPrefix, String name, ID id, Class<R> clazz, Function<ID, R> dbSelect, Long exp, TimeUnit timeUnit)   {
    String dataKey = dataKeyPrefix + id;
    String lockName = name + ":" + id;

    // 1. 查缓存
    String dataJson = redisTemplate.opsForValue().get(dataKey);

    // 2. 空值则直接返回，防止缓存穿透
    if ("".equals(dataJson)) {
        log.debug("缓存告知店铺不存在：{}", id);
        return null;
    }

    // 3. 不存在则直接返回，没有配置热键
    if (StrUtil.isBlank(dataJson)) {
        log.debug("热点 Key 丢失：{}", dataKey);
        return null;
    }

    // 4. 获取缓存对象
    RedisDataWithExp redisData = JSONUtil.toBean(dataJson, RedisDataWithExp.class);
    R r = JSONUtil.toBean((JSONObject) redisData.getData(), clazz);

    // 5. 没过期则直接返回
    if (redisData.getExpireTime().isAfter(LocalDateTime.now())) {
        log.debug("缓存查到未过期店铺：{}", id);
        return r;
    }

    // 6. 过期则获取锁来重建，防止缓存击穿
    RedisLock redisLock = new RedisLock(lockName, redisTemplate);
    boolean isLock = redisLock.tryLock(LOCK_TTL);

    // 7. 异步重建
    if (isLock) {
        asyncRebuildThread.submit(() -> {
            try {
                // 7.1 查数据库
                R db_r = dbSelect.apply(id);

                // 7.2 写缓存
                if (db_r == null) {
                    this.setData(dataKey, "", CACHE_NULL_TTL, timeUnit);
                    log.debug("数据库告知店铺不存在：{}", id);
                } else {
                    this.setDataWithExp(dataKey, db_r, exp, timeUnit);
                    log.debug("数据库查到店铺：{}", id);
                }
            } finally {
                // 7.3 释放锁
                redisLock.unlock();
            }
        });
    }
    log.debug("缓存查到已过期店铺：{}", id);
    return r;
}
```



## 防竞争

竞争指的是：**当多个请求同时对同一资源进行修改时，需要确保数据的一致性**。在项目中涉及的场景是，抢购秒杀券时大量订单信息需要写入数据库，需要确保：

- **不得超卖**：库存必须更新正确，不能最后是负数
- **不能少卖**：如果请求大于库存，那么最终一定要把库存卖完
- **不得错卖**：库存-1就代表订单+1（事务）

在这个业务中，造成竞争的原因是**在判断库存 → 扣减库存 → 创建订单的期间，别的线程会对数据库的库存进行更改，导致数据不一致性**，从而引发各种各样的问题。

### 乐观锁

乐观锁的思想是**认为数据冲突只是小概率事件，不会去加锁阻塞，而是到真正写数据库的时候，再来判断是否会引发数据不一致**。

在这里就可以先记录查到的库存值 stock，然后在执行 update 的时候加一个判断条件，即当前库存是不是之前查到的库存。但这样做有个很大的弊端，那就是当并发量很大的时候，**唯一成功的请求反而是导致其他大部分请求失败的罪魁祸首**，所以即使可以多次重试，最后也只有极少数请求成功执行，即发生了严重的少卖。

```java
public Result createOrderByOptimisticLock(Long voucherId) {
    // 查询优惠券
    SeckillVoucher sv = seckillVoucherService.getById(voucherId);
    if (sv == null)                                     return Result.fail("秒杀券不存在！");
    if (sv.getBeginTime().isAfter(LocalDateTime.now())) return Result.fail("活动未开始！");
    if (sv.getEndTime().isBefore(LocalDateTime.now()))  return Result.fail("活动已结束！");

    // 乐观锁
    Long userId = ThreadLocalUserUtil.getUser().getId();
    for (int i = 0; i < MAX_TRY; i++) {
        // 1. 是否购买过
        Long count = query().eq("user_id", userId).eq("voucher_id", voucherId).count();
        if (count > 0) {
            log.debug("不允许重复抢购：用户={}，优惠券={}", userId, voucherId);
            return Result.fail("不允许重复抢购！");
        }

        // 2. 是否有库存
        Integer stock = seckillVoucherService.getById(voucherId).getStock();
        if (stock < 1) {
            log.debug("抢购失败，库存不足：{}", voucherId);
            return Result.fail("库存不足！");
        }

        // 3. 是否购买成功
        boolean success = seckillVoucherService.update()
                .setSql("stock = stock - 1")
                .eq("voucher_id", voucherId)
                .eq("stock", stock)
                .update();

        // 4. 下订单
        if (success) {
            VoucherOrder voucherOrder = new VoucherOrder();
            voucherOrder.setId(redisId.nextId(ORDER_PREFIX));
            voucherOrder.setVoucherId(voucherId);
            voucherOrder.setUserId(userId);
            save(voucherOrder);
            log.debug("抢购成功，添加订单：{}", voucherOrder);
            return Result.ok(voucherOrder.getId());
        }

        // 5. 等待时间
        int delay = (1 << i) * WAIT_BASE + random.nextInt(WAIT_JITTER);
        ThreadUtil.sleep(delay);
    }
    log.debug("抢购失败：用户={}，优惠券={}", userId, voucherId);
    return Result.fail("抢购失败！");
}
```

### 悲观锁

悲观锁的思想是**认为数据冲突是不可忍受的，所有请求都必须拿到锁才能对数据库进行操作**。

悲观锁可以处理一定的并发量，但由于加锁机制和重试机制，响应时间会相对较长，而且极高并发下仍然会有失败的概率。

```java
public Result createOrderByPessimisticLock(Long voucherId) {
    // 查询优惠券
    SeckillVoucher sv = seckillVoucherService.getById(voucherId);
    if (sv == null)                                     return Result.fail("秒杀券不存在！");
    if (sv.getBeginTime().isAfter(LocalDateTime.now())) return Result.fail("活动未开始！");
    if (sv.getEndTime().isBefore(LocalDateTime.now()))  return Result.fail("活动已结束！");

    // 悲观锁
    Long userId = ThreadLocalUserUtil.getUser().getId();
    String lockName = ORDER_PREFIX + userId;
    RedisLock redisLock = new RedisLock(lockName, redisTemplate);
    try {
        for (int i = 0; i < MAX_TRY; i++) {
            // 加锁
            Boolean isLock = redisLock.tryLock(LOCK_TTL);
            if (isLock) {
                // 1. 是否购买过
                Long count = query().eq("user_id", userId).eq("voucher_id", voucherId).count();
                if (count > 0) {
                    log.debug("不允许重复抢购：用户={}，优惠券={}", userId, voucherId);
                    return Result.fail("不允许重复抢购！");
                }

                // 2. 是否有库存
                Integer stock = seckillVoucherService.getById(voucherId).getStock();
                if (stock < 1) {
                    log.debug("抢购失败，库存不足：{}", voucherId);
                    return Result.fail("库存不足！");
                }

                // 3. 是否购买成功
                boolean success = seckillVoucherService.update()
                        .setSql("stock = stock - 1")
                        .eq("voucher_id", voucherId)
                        .update();

                // 4. 下订单
                if (success) {
                    VoucherOrder voucherOrder = new VoucherOrder();
                    voucherOrder.setId(redisId.nextId(ORDER_PREFIX));
                    voucherOrder.setVoucherId(voucherId);
                    voucherOrder.setUserId(userId);
                    save(voucherOrder);
                    log.debug("抢购成功，添加订单：{}", voucherOrder);
                    return Result.ok(voucherOrder.getId());
                }
            }

            // 5. 等待时间
            int delay = (1 << i) * WAIT_BASE + random.nextInt(WAIT_JITTER);
            ThreadUtil.sleep(delay);
        }
        log.debug("抢购失败：用户={}，优惠券={}", userId, voucherId);
        return Result.fail("抢购失败！");
    } finally {
        redisLock.unlock();
    }
}
```

### 消息队列

#### Stream

上述两个锁机制的核心思想都是**在当下线程能处理当场处理，不能处理就等待**。如果可以**把并发转变为串行，让后台异步线程一个接着一个处理**，那么请求线程就完全不需要考虑对数据库的操作，只需要把操作托付给后台线程，自己就可以立马响应。

这种思想就是**消息队列的削峰填谷，即异步串行处理，由请求线程作为生产者投递数据库操作，由后台线程作为消费者执行数据库操作**。通常情况可以利用消息中间件如 RabbitMQ、RocketMQ 处理，但是在这里也可以利用 Redis 的 Stream 结构来模拟实现消息中间件。

1. 创建流和消费组：0 表示从最早的消息开始消费，MKSTREAM 表示不存在 stream 就创建，这个需要事先在 Redis 准备好

    ```redis
    XGROUP CREATE mystream mygroup 0 MKSTREAM
    ```

2. 生产者写消息：消息内容是 field-value 形式的键值对

    ```redis
    XADD mystream * field value [field value...]
    ```

3. 消费者读消息：从指定流和指定消费组中读取 count 条消息，如果等待 block 后没有消息则返回 nil， 0 表示从头开始读取未被消费的消息，

    ```redis
    XREADGROUP GROUP mygroup myconsumer COUNT count BLOCK block STREAMS mystream 0
    ```

4. 消费者确认消息：只有确认了才算正式消费消息，否则消息会在 pending list 中

    ```redis
    XACK mystream mygroup message-id
    ```

#### 消费逻辑

在项目中，事先使用 ExecutorService 对象得到单后台异步线程，然后执行消费者逻辑，即保存订单-扣减库存-确认消息，**同时在出现错误的情况下还要处理 pending list 的消息，防止消息未被处理，导致错卖的情况**。

```java
public class RedisStream {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private IVoucherOrderService voucherOrderService;

    @Autowired
    private ISeckillVoucherService seckillVoucherService;

    @Autowired
    @Qualifier("orderMQThreads")
    private ExecutorService orderMQThreads;

    // 创建 Bean 之后开启线程池来处理异步任务
    @PostConstruct
    private void init() {
        orderMQThreads.submit(new VoucherOrderHandler());
    }

    // 正常消费处理
    private class VoucherOrderHandler implements Runnable {
        @Override
        public void run() {
            while (true) {
                try {
                    List<MapRecord<String, Object, Object>> messageList = redisTemplate.opsForStream().read(
                            Consumer.from(SECKILL_GROUP_NAME, SECKILL_CONSUMER_NAME),
                            StreamReadOptions.empty().count(1).block(Duration.ofSeconds(2)),
                            StreamOffset.create(SECKILL_STREAM_NAME, ReadOffset.lastConsumed())
                    );
                    if (messageList == null || messageList.isEmpty()) {
                        continue;
                    }
                    processMessage(messageList.get(0));
                } catch (Exception e) {
                    log.debug("订单处理异常：{}", e.getMessage());
                    handlePendingList();
                }
            }
        }
    }

    // pending 消费处理
    private void handlePendingList() {
        while (true) {
            try {
                List<MapRecord<String, Object, Object>> messageList = redisTemplate.opsForStream().read(
                        Consumer.from(SECKILL_GROUP_NAME, SECKILL_CONSUMER_NAME),
                        StreamReadOptions.empty().count(1),
                        StreamOffset.create(SECKILL_STREAM_NAME, ReadOffset.from("0"))
                );
                if (messageList == null || messageList.isEmpty()) {
                    break;
                }
                processMessage(messageList.get(0));
            } catch (Exception e) {
                log.error("订单处理错误：{}", e.getMessage());
                ThreadUtil.sleep(1000);
            }
        }
    }

    // 将订单添加到数据库，并在缓存中确认消息
    private void processMessage(MapRecord<String, Object, Object> message) {
        Map<Object, Object> orderMap = message.getValue();
        VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(orderMap, new VoucherOrder(), true);

        // 保存订单
        voucherOrderService.save(voucherOrder);

        // 库存减一
        seckillVoucherService.update()
                .setSql("stock = stock - 1")
                .eq(VOUCHER_ID, voucherOrder.getVoucherId())
                .update();

        // 确认消息
        redisTemplate.opsForStream().acknowledge(SECKILL_STREAM_NAME, SECKILL_GROUP_NAME, message.getId());
        log.debug("抢购成功，添加订单，库存减一：{}", voucherOrder.getVoucherId());
    }
}
```

#### 业务逻辑

为了实现操作串行，需要确保对 Redis 的操作不会有并发风险，所以必须使用 Lua 脚本来合并为一个原子操作，同时**请求线程只要把消息放到了消息队列，就相当于将写数据库操作完全交付给后台异步线程来处理，因此可以直接响应成功**。

```java
public Result createOrderByRedisStream(Long voucherId) {
    // 查询优惠券
    SeckillVoucher sv = seckillVoucherService.getById(voucherId);
    if (sv == null)                                     return Result.fail("秒杀券不存在！");
    if (sv.getBeginTime().isAfter(LocalDateTime.now())) return Result.fail("活动未开始！");
    if (sv.getEndTime().isBefore(LocalDateTime.now()))  return Result.fail("活动已结束！");

    // 1. 创建 Lua 脚本
    DefaultRedisScript<Long> redisScript = new DefaultRedisScript<>();
    redisScript.setLocation(new ClassPathResource("lua/mq.lua"));
    redisScript.setResultType(Long.class);

    // 2. 构造 key 和 argv
    String stockKey = SECKILL_STOCK_KEY + voucherId;
    String orderKey = SECKILL_ORDER_KEY + voucherId;
    String streamKey = SECKILL_STREAM_NAME;
    Long userId = ThreadLocalUserUtil.getUser().getId();
    Long orderId = redisId.nextId(ORDER_PREFIX);

    // 3. 执行脚本
    int result = redisTemplate.execute(
            redisScript,
            Arrays.asList(stockKey, orderKey, streamKey),
            String.valueOf(userId),
            String.valueOf(voucherId),
            String.valueOf(orderId)
    ).intValue();

    // 4. 可以确定操作只要投递就不会失败
    if (result == 1) {
        log.debug("抢购失败，库存不足：{}", voucherId);
        return Result.fail("库存不足！");
    } else if (result == 2) {
        log.debug("不允许重复抢购：{}", voucherId);
        return Result.fail("不允许重复抢购！");
    } else {
        return Result.ok(orderId);
    }
}


/* Lua 脚本

local orderId = ARGV[3]

local stock = tonumber(redis.call('get', stockKey))

-- 判断库存是否足够
if stock <= 0 then
    return 1
    
-- 判断用户是否已经下单
elseif redis.call('sismember', orderKey, userId) == 1 then
    return 2
    
-- 将下单消息加入队列
else
    redis.call('decr', stockKey)
    redis.call('sadd', orderKey, userId)
    redis.call('xadd', streamKey, '*', 'userId', userId, 'voucherId', voucherId, 'id', orderId)
    return 0
end
*/
```



## 滚动分页：ZSet

### 推送

不再需要用户主动去搜被关注人的博客，而是只要被关注人一发博客，就把博客 id 放到关注人对应的列表之中，这样就可以实现关注人一键查询所有被关注人的博客。

```java
public Result postBlog(Blog blog) {
    // 1. 获取用户
    Long userId = ThreadLocalUserUtil.getUser().getId();
    blog.setUserId(userId);

    // 2. 保存博客
    boolean success = save(blog);
    if (!success) {
        return Result.fail("发布博客失败！");
    }

    // 3. 查询关注人
    List<Follow> followUsers = followService.query().eq("follow_user_id", userId).list();

    // 4. 推送博客到关注人
    Long blogId = blog.getId();
    for (Follow followUser : followUsers) {
        Long followUserId = followUser.getUserId();
        String key = FEED_KEY + followUserId;
        redisTemplate.opsForZSet().add(key, String.valueOf(blogId), System.currentTimeMillis());
        log.debug("用户 {} 推送了博客 {} 到用户 {}", userId, blogId, followUserId);
    }

    return Result.ok(blog.getId());
}
```

### 滚动

**滚动分页查询（又称游标分页、Seek 分页）** 不依赖传统分页中的偏移量 offset，而是**通过记录上一次查询时的有序字段（如时间戳、热度、评论数等）的末尾值，作为下一次查询的起点，从该位置继续向后读取固定数量的数据**，前端只需维护已加载的数据，并按照有序字段的顺序进行展示，即可实现连续滚动加载。

- 性能稳定：每次都只查询 O(pageSize)，不会因为页数变大而变慢
- 一致性好：在高并发的情况下，只依赖于有序字段，不依赖于数据顺序，不会出现数据重复和丢失的情况
- 天然适合大数据量的推送流：朋友圈、评论区、短视频，只有往下滑才会出现新的内容

在 Redis 中，可以使用 ZSet 存储数据，**其中 member 存储数据 ID，而 score 存储时间戳**，利用时间戳这个有序字段，可以实现滚动分页查询。因此前端需要在请求时带上上一次查询的最小时间戳（lastTime） 和相同时间戳下的偏移量（offset）

```redis
ZREVRANGEBYSCORE key minScore maxScroe WITHSCORES LIMIT offset count
```

- ZREVRANGEBYSCORE：时间戳越大，内容越新，排序越前，所以是倒序排序
- maxScroe：当前查询的最大值就是上一次查询的最小时间戳 lastTime
- minScore：当前查询的最小值始终为 0，表示查询全部
- offset：约定初始为 0 之后为 1，表示相同时间戳下最多只有一条数据
- count：每次查询的数量，设置为常量

```java
SELECT * FROM blog WHERE id IN (...) ORDER BY FIELD(id, ...);
```

- Redis 只是查到了博客 id，具体博客内容还需要在数据库中查询
- 如果只是用 in 条件，MySQL 不能保证结果顺序和 IN 的顺序一致
- 需要用 ORDER BY FIELD，手动指定排序的键和排序顺序

```java
public Result queryFollowBlog(Long lastTime, Integer offset) {
    // 1. 获取用户
    Long userId = ThreadLocalUserUtil.getUser().getId();

    // 2. 分页查询博客id
    String key = FEED_KEY + userId;
    Set<ZSetOperations.TypedTuple<String>> typedTuples = redisTemplate
            .opsForZSet()
            .reverseRangeByScoreWithScores(key, 0, lastTime, offset, SCROLL_COUNT);
    if (typedTuples == null || typedTuples.isEmpty()) {
        return Result.ok();
    }

    // 3. 获取博客id
    List<Long> blogIds = new ArrayList<>(typedTuples.size());
    for (ZSetOperations.TypedTuple<String> typedTuple : typedTuples) {
        blogIds.add(Long.valueOf(typedTuple.getValue()));
        lastTime = typedTuple.getScore().longValue();
    }

    // 4. 按顺序获取博客
    String blogIdsStr = StrUtil.join(",", blogIds);
    List<Blog> blogs = query().in("id", blogIds).last("ORDER BY FIELD(id," + blogIdsStr + ")").list();

    // 5. 补充博客信息
    for (Blog blog : blogs) {
        addUserDetailToBlog(blog);
    }

    // 6. 封装结果返回
    ScrollDTO scrollDTO = new ScrollDTO();
    scrollDTO.setList(blogs);
    scrollDTO.setOffset(SCROLL_OFFSET);
    scrollDTO.setMinTime(lastTime);
    log.debug("查询关注人的博客：{}", blogIdsStr);
    return Result.ok(scrollDTO);
}
```



## 位置查询：GEO

### 插入位置

```redis
GEOADD key x y member [x y member ...]
```

- key：存放地理位置数据的集合键
- x，y：经纬度
- member：该坐标对应的标识

在 Java 中，需要为每一个位置先指定一个标识，然后用经纬度构造 RedisGeoCommands.GeoLocation 对象来添加到 GEO 中。

```java
private void putShopLocationIntoRedis() {
    // 1. 获取店铺
    List<Shop> shopList = shopService.list();

    // 2. 按类型分组
    Map<Long, List<Shop>> shopsMapByType = shopList.stream().collect(Collectors.groupingBy(Shop::getTypeId));

    // 3. 按类型写缓存
    for (Map.Entry<Long, List<Shop>> shopsByType : shopsMapByType.entrySet()) {
        Long typeId = shopsByType.getKey();
        String key = SHOP_GEO_KEY + typeId;

        List<Shop> shops = shopsByType.getValue();
        List<RedisGeoCommands.GeoLocation<String>> locations = new ArrayList<>();
        for (Shop shop : shops) {
            locations.add(new RedisGeoCommands.GeoLocation<>(
                    shop.getId().toString(),
                    new Point(shop.getX(), shop.getY())
            ));
        }

        redisTemplate.opsForGeo().add(key, locations);
    }

    log.debug("店铺位置预热成功");
}
```

### 查找位置

```redis
GEOSEARCH key FROMLONLAT x y BYRADIUS radius WITHDIST COUNT count
```

- key：GEO 集合的键
- x，y：给定的经纬度
- radius：以 (x,y) 为中心的半径范围
- count：从小到大的查询个数

在 Java 中执行 GEO 查询后会返回一个 GeoResults 对象。通过 getContent() 可以获得包含若干 GeoResult 的列表，每个 GeoResult 中包含了成员标识、经纬度坐标以及距离等信息，获取到这些标识后，再结合数据库查询即可获取店铺的完整业务数据。

除此之外，由于 GEO 的底层本质是 ZSet，可以利用 **skip(from) + limit(end)** 截取当前页的数据，实现了基于距离顺序的分页查询。

```java
@Override
public Result queryShopByType(Integer typeId, Integer current, Double x, Double y) {
    // 类型查询
    if (x == null || y == null) {
        Page<Shop> page = query().eq("type_id", typeId).page(new Page<>(current, SystemConstants.DEFAULT_PAGE_SIZE));
        log.debug("按照类型查询店铺：{}", typeId);
        return Result.ok(page.getRecords());
    }
    // 地理查询
    else {
        // 1. 获取参数
        int from = (current - 1) * SystemConstants.DEFAULT_PAGE_SIZE;
        int end = from + SystemConstants.DEFAULT_PAGE_SIZE;
        String key = SHOP_GEO_KEY + typeId;

        // 2. 范围查询
        GeoResults<RedisGeoCommands.GeoLocation<String>> geoResults = redisTemplate.opsForGeo().search(
                key,
                GeoReference.fromCoordinate(x, y),
                new Distance(5000),
                RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end)
        );
        if (geoResults == null || geoResults.getContent().size() <= from) {
            return Result.ok(Collections.emptyList());
        }

        // 3. 获取位置、id和距离
        List<GeoResult<RedisGeoCommands.GeoLocation<String>>> shopLocations = geoResults.getContent();
        List<Long> shopIds = new ArrayList<>();
        Map<String, Distance> shopDistances = new HashMap<>();
        shopLocations.stream().skip(from).forEach(shopLocation -> {
            String shopIdStr = shopLocation.getContent().getName();
            shopIds.add(Long.valueOf(shopIdStr));
            Distance distance = shopLocation.getDistance();
            shopDistances.put(shopIdStr, distance);
        });

        // 4. 获取店铺
        String shopIdsStr = StrUtil.join(",", shopIds);
        List<Shop> shops = query().in("id", shopIds).last("ORDER BY FIELD(id, "+ shopIdsStr + ")").list();

        // 5. 设置距离
        for (Shop shop : shops) {
            Double metre = shopDistances.get(shop.getId().toString()).getValue();
            shop.setDistance(metre);
        }

        log.debug("按照地理位置查询店铺：x={}, y={}", x, y);
        return Result.ok(shops);
    }
}
```



## 签到记录：BitMap

### 添加

如果用一个整型 0/1 来表示签到与否，那么签到 100 天就需要 100 x 4 = 400B，100 个人就是 100 x 400 = 40000B；如果用一位 0/1 来表示签到与否，那么签到 100 天就需要 100b，100 个人就是 100 x 100 = 10000b = 1250B。也就是说，使用 BitMap 比使用 String 节约了 32 倍的空间！

```redis
SETBIT key offset value
```

实际上，BitMap 底层是通过 String 实现的，因为 String 在 Redis 中就是使用二进制来存储的，而且 Redis 不会校验二进制数据的格式，存什么位就是什么位，在 Java 中是利用 opsForValue 的 setBit 函数来置位。

```java
public Result sign() {
    // 1. 获取用户
    Long userId = ThreadLocalUserUtil.getUser().getId();

    // 2. 构造 key
    LocalDate now = LocalDate.now();
    String datePrefix = now.format(DateTimeFormatter.ofPattern("yyyyMM"));
    String key = SIGN_KEY + userId + ":" + datePrefix;

    // 3. 获取天
    int dayOffset = now.getDayOfMonth();

    // 4. 写入缓存
    redisTemplate.opsForValue().setBit(key, dayOffset - 1, true);
    log.debug("用户 {} 在当月的第 {} 天签到", userId, dayOffset);
    return Result.ok();
}
```

### 查询

- 如果是获取总签到天数，只需要使用 BITCOUNT 即可当前数据中所有位为 1 的个数
- 如果是获取连续签到天数，需要先获取二进制位表示的整数，然后通过对 1 与操作和按位右移操作来逐个判断最低位是不是 1。

```java
public Result signCount() {
    // 1. 获取用户
    Long userId = ThreadLocalUserUtil.getUser().getId();

    // 2. 构造 key
    LocalDate now = LocalDate.now();
    String datePrefix = now.format(DateTimeFormatter.ofPattern("yyyyMM"));
    String key = SIGN_KEY + userId + ":" + datePrefix;

    // 3. 获取数据
    int dayOffset = now.getDayOfMonth();
    int count = 0;
    List<Long> results = redisTemplate.opsForValue().bitField(
            key,
            BitFieldSubCommands
                    .create()
                    .get(BitFieldSubCommands.BitFieldType.unsigned(dayOffset))
                    .valueAt(0)
    );
    Long total = redisTemplate.execute((RedisCallback<Long>) connection ->
            connection.stringCommands().bitCount(key.getBytes())
    );

    // 4. 位运算：计数连续签到
    if (results == null || results.isEmpty() || results.get(0) == null || results.get(0) == 0) {
        return Result.ok();
    }
    else {
        Long num = results.get(0);
        while (true) {
            if ((num & 1) == 0) {
                break;
            } else {
                count = count + 1;
                num = num >> 1;
            }
        }
    }
  
  	// 5. 输出结果
    log.debug("用户 {} 目前连续签到了 {} 天", userId, count);
    log.debug("用户 {} 当月一共签到了 {} 天", userId, total);
    return Result.ok();
}
```



## 访问统计：HyperLogLog

HyperLogLog 是一个专门用于计算唯一值个数的数据结构，它内部是采用了概率算法来估计总数，并不是传统的计数器，只提供了 add（添加数据）、delete（删除数据）、size（获取数量） 和 union（合并数据） 四种基本方法，通常在拦截器中使用来统计：

- **UV：用户浏览量，对用户的请求进行计数**
- **PV：页面浏览量，对路径的请求进行计数**

```java
// UV
public class UserViewInterceptor implements HandlerInterceptor {

    private final StringRedisTemplate redisTemplate;

    public UserViewInterceptor(StringRedisTemplate redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        UserDTO userDTO = ThreadLocalUserUtil.getUser();
        if (userDTO != null) {
            String key = USER_VIEW_KEY + userDTO.getId();
            String value = UUID.randomUUID().toString(true) + System.currentTimeMillis();
            redisTemplate.opsForHyperLogLog().add(key, value);
            log.debug("用户 {} 允许请求：{}", userDTO.getNickName(), request.getRequestURI());
            return true;
        } else {
            log.debug("用户不存在！拦截非白名单请求：{}", request.getRequestURI());
            return false;
        }
    }
}

// PV
public class PageViewInterceptor implements HandlerInterceptor {
    private final StringRedisTemplate redisTemplate;

    public PageViewInterceptor(StringRedisTemplate redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        String value = UUID.randomUUID().toString(true) + System.currentTimeMillis();
        String key = PAGE_VIEW_KEY + request.getRequestURI();
        redisTemplate.opsForHyperLogLog().add(key, value);
        return true;
    }
}

```
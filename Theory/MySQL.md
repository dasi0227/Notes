# MySQL



* [MySQL](#mysql)
   * [基本概念](#基本概念)
   * [层级架构](#层级架构)
      * [客户层](#客户层)
      * [服务层](#服务层)
      * [引擎层](#引擎层)
      * [存储层](#存储层)
      * [更新语句的执行过程](#更新语句的执行过程)
   * [字段类型](#字段类型)
      * [数值类型](#数值类型)
      * [字符串类型](#字符串类型)
      * [日期时间类型](#日期时间类型)
      * [NULL](#null)
   * [日志](#日志)
      * [slow query log](#slow-query-log)
      * [binlog](#binlog)
      * [redo log](#redo-log)
      * [undo log](#undo-log)
      * [区别](#区别)
   * [事务](#事务)
      * [ACID](#acid)
      * [并发事务问题](#并发事务问题)
      * [事务隔离级别](#事务隔离级别)
   * [锁](#锁)
      * [共享锁/排他锁](#共享锁排他锁)
      * [表级锁](#表级锁)
      * [意向锁](#意向锁)
      * [行级锁](#行级锁)
      * [自增锁](#自增锁)
   * [MVCC](#mvcc)
      * [定义](#定义)
      * [实现机制](#实现机制)
      * [执行过程](#执行过程)
   * [索引](#索引)
      * [定义](#定义)
      * [索引类别](#索引类别)
      * [组合索引](#组合索引)
      * [索引方式](#索引方式)
      * [索引失效](#索引失效)
   * [存储结构](#存储结构)
      * [表空间](#表空间)
      * [COMPACT 行](#compact-行)
      * [B+ 树结构](#b-树结构)
   * [性能优化](#性能优化)
      * [EXPLAIN](#explain)
      * [读写分离](#读写分离)
      * [分库分表](#分库分表)
      * [分片](#分片)
   * [SQL 优化](#sql-优化)
      * [避免使用 SELECT *](#避免使用-select-)
      * [避免使用外键、级联、连接](#避免使用外键级联连接)
      * [深度分页优化](#深度分页优化)



## 基本概念

**RDB（Relational Database, 关系系数据库）**是一种建立在关系模型基础上的数据库，数据以**表格（Table）**的形式组织，每张表由**行（Row）和列（Column）**组成，利用**主键和外键**实现数据间的**一对多、一对一和多对多**关系

**SQL（Structured Query Language, 结构化查询语言）**是用来与数据库交互的**通用声明式语言**，又可以细分为

- **DDL（Data Definition Language）**：定义数据库结构，如 CREATE、ALTER、DROP、TRUNCATE
- **DML（Data Manipulation Language）**：对表中数据进行操作，如 SELECT、INSERT、UPDATE、DELETE
- **DCL （Data Control Language）**：用来控制数据库的权限和访问，如 GRANT、REVOKE
- **TCL（Transaction Control Language）**：用来管理数据库事务，如 COMMIT、ROLLBACK、SAVEPOINT

**MySQL** 是一种实现了 RDB 并支持 SQL 语法的数据库系统，MySQL 由于其**开源免费、成熟稳定、功能完善、文档丰富、兼容性好、高可用、高性能**等优点，广泛使用在各类系统之中



## 层级架构

![image-20250924161001518](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509241610627.png)

### 客户层

- **请求**：客户端工具（mysql 命令行、JDBC/ODBC 驱动、 MySQL Workbench）会通过网络协议发送 SQL 请求到 MySQL 服务端，默认监听端口号为 3306
- **响应**：客户端工具会将返回来的二进制流按照协议解析，结果会被包装成编程语言中的对象，或者渲染为表格形式的文本呈现

### 服务层

- **连接器**：负责管理客户端和服务器之间的连接，进行用户的身份认证（用户名/密码/IP）
- **查询缓存**：会缓存 SQL 语句和对应的结果，需要额外处理，实际业务中不仅命中率低而且存在频繁更新和替换，因此在 8.0 后移除
- **分析器**：先进行词法分析，提取出关键字、表名、字段名和其他语句，然后进行语法分析，生成语法树，检查 SQL 合法性，出现错误会返回错误码
- **优化器**：生成执行计划，考虑使用哪个索引以及 JOIN 的顺序，估算每个方案的执行代价，选择最优方案执行
- **执行器**：先进行权限校验（是否允许执行），然后调用存储引擎的接口执行 SQL 操作

### 引擎层

存储引擎是**表级别的底层实现机制**，负责数据的**存储和读取**，决定了一张表的**数据、索引、日志、事务、锁**是如何存储和管理的

| **特性**     | InnoDB | **MyISAM** | Memory |
| ------------ | ------ | ---------- | ------ |
| **存储位置** | 磁盘   | 磁盘       | 内存   |
| **锁粒度**   | 行级锁 | 表级锁     | 表级锁 |
| **读写性能** | 快     | 慢         | 极快   |
| **事务支持** | ✅      | ❌          | ❌      |
| **外键支持** | ✅      | ❌          | ❌      |
| **恢复支持** | ✅      | ❌          | ❌      |
| **聚簇索引** | ✅      | ❌          | ❌      |

### 存储层

- **.ibd 文件**：记录一个表的数据和索引，用于持久化存储
- **ibdata**：记录全局元数据，包括表的数据字典、表空间映射和内部系统表，用于解析数据
- **redo log**：记录数据页的物理修改，用于崩溃恢复
- **undo log**：记录数据修改前的旧值，用于事务回滚
- **binlog**：记录 SQL 操作，用于主从复制、增量备份和数据恢复

### 更新语句的执行过程

```sql
UPDATE student SET age = 20 WHERE id = 1;
```

1. 客户端发送 SQL 语句到 MySQL 服务端
2. 服务端
    1. 连接器对用户身份进行校验
    2. 分析器解析语句并确认没有语法错误
    3. 优化器确定的执行方案
    4. 执行器先检查用户是否有对表/列的操作权限，再调用存储引擎的接口执行 SQL 语句
3. 存储引擎
    1. 通过索引在 .ibd 文件找到对应的数据页加载到 Buffer Pool，并对目标行进行加锁
    2. 写 undo log，记录旧值，并在 Buffer Pool 中修改数据
    3. 写 redo Log，记录物理操作，并通知执行器
4. 服务端
    1. 执行器写 binlog，记录 SQL 语句
    2. 调用存储引擎的接口提交事务



## 字段类型

### 数值类型

整数

- **TINYINT**：1 字节，范围 ±128～127
- **SMALLINT**：2 字节，范围约 ±3万
- **MEDIUMINT**：3 字节，范围约 ±800万
- **INT**：4 字节，范围约 ±21亿
- **BIGINT**：8 字节，范围约 ±900万兆

> 整型具有一个 **UNSIGNED 属性，可以令最高位不用作正负符号位，统一为正数**，因此最高位也用作数值位，即**把正整数的上限提高一倍，下限为 0**

浮点数

- **FLOAT**：4 字节，单精度浮点数，大约能保证 6～7 位有效数字
- **DOUBLE**：8 字节，双精度浮点数，大约能保证 15~16 位有效数字
- **DECIMAL(M, D) / NUMERIC(M, D)**：动态大小，精确精度，M 指定总位数，D 指定小数位数

### 字符串类型

- **CHAR(M)**：定长字符串，最长 255 字符，如果不足长度会用空格符号补齐
- **VARCHAR(M)**：变长字符串，最大 65535 字节，如果不足长度不会补齐，但是底层会额外用 1～2 字节存实际长度
- **TEXT**：文本，分为 TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT
- **BLOB**：二进制数据，分为 TINYBLOB、BLOB、MEDIUMBLOB、LONGBLOB

> 内存分别占据：255B - 64KB - 16MB - 4GB

### 日期时间类型

- **YEAR**：YYYY，占 1 字节
- **TIME**：HH:MM:SS，占 3 字节
- **DATE**：YYYY-MM-DD，占 3 字节
- **DATETIME**：YYYY-MM-DD HH:MM:SS，占 8 字节，存储字面量，存啥取啥
- **TIMESTAMP**：YYYY-MM-DD HH:MM:SS，占 4 字节，存储时会自动转为 UTC，读取时再根据当前时区转为本地时间

### NULL

NULL 在 MySQL 中表示”**未知**“，它既不表示”零“，也不表示“错”，甚至不能完全表示为”空“

- NULL 的语义**既可以是不存在值，也可以是不知道值**
- NULL 与任何值（包括 NULL）比较运算的结果都是 UNKNOWN
- NULL 与任何值（包括 NULL）算术运算的结果都是 NULL
- NULL 与任何值（包括 NULL）逻辑运算的结果，除非是短路，否则都是 NULL
- 除了 `COUNT(*)` 的所有聚合函数都会忽略 NULL
- 在 `ORDER BY` 中，NULL 会被当作最小值
- 只能通过 `IS NULL` 和 `IS NOT NULL` 来判断，而不能通过 `= NULL`

在实际业务中，通常会给每一列加上 `NOT NULL DEFAULT x` 来约束非空，并且设置当插入未指定值时填充的默认值

1. 存储层面：如果表的任何一列可以为 NULL，那么 MySQL 会为这个表中的每一行维护一个 bitmap，来标志这些列是否为 NULL，造成额外存储开销
2. 运算层面：在运算之前可能都需要先判断 `IS NULL` 和 `IS NOT NULL` 
3. 索引层面：B+Tree/Hash 都要特殊处理 NULL，会降低索引效率
4. 兼容层面：在 ORM 框架中需要额外判断 NULL，否则会出现 NullPointerException 异常



## 日志

### slow query log

慢查询日志记录了**执行时间超过最长时间阈值的所有查询语句**

```sql
-- 查看慢查询日志是否开启
SHOW VARIABLES LIKE "slow_query_log";

-- 查看慢查询语句数量
SHOW GLOBAL STATUS LIKE "%Slow_queries%";

-- 查看慢查询时间阈值（默认 10s）
SHOW VARIABLES LIKE "%long_query_time%";
```

### binlog

binlog 记录了对 MySQL 数据执行了更改的所有操作，包括 DDL 和 DML，但不包括 SELECT 和 SHOW 这类查询操作，由于 binlog 是随着 MySQL 运行不断动态追加的，当到达最大阈值后，会生成新的文件来保存日志，文件名为 `mysql-bin.00000x`，x 按序递增，如果开启了事务，**每条修改语句产生的 binlog event 会先写入当前线程的 binlog cache**，当事务提交时才会将 binlog cache 的内容一次性写入 binlog 文件

- **数据恢复**：binlog 会保存时间戳信息，可以结合全量备份的时间点，从指定时间点开始恢复
- **主从复制**：从库通过 I/O 线程读取主库 binlog 并写入 relay log，再由 SQL 线程重放，实现数据的复制和同步
- **增量订阅**：Canel 等中间件根据交互协议把自己伪装成 Slave 节点，从而向 Master 请求并解析 binlog，将捕获到的数据库变更事件投递到消息队列，供第三方同步或通知

```sql
-- 查看是否启用 binlog
SHOW VARIABLES LIKE 'log_bin';

-- 查看 binlog 文件的最大大小
SHOW VARIABLES LIKE 'max_binlog_size';

-- 查看 binlog 缓存的大小
SHOW VARIABLES LIKE '%binlog_cache_size%';

-- 查看 binlog 文件的格式（Statement、ROW、Mixed）
SHOW ENGINE INNODB STATUS\GSHOW VARIABLES LIKE 'innodb_log_files_in_group';SHOW VARIABLES LIKE 'innodb_flush_log_at_trx_commit';

-- 查看 binlog 刷盘的事务数（0 依赖 OS）
SHOW VARIABLES LIKE '%sync_binlog%'; 

-- 查看所有 binlog 日志文件
SHOW BINARY LOGS;

-- 查看当前正在写的 binlog 文件和位置
SHOW MASTER STATUS;
```

### redo log

redo log 是 InnoDB 存储引擎独有的日志文件，它记录的是数据页的物理修改，主要用于崩溃恢复

**WAL（Write Ahead Logging）** ：即使崩溃导致 Buffer Pool 刷盘失败，只要 Redo Log 落盘成功，事务就算持久化成功，可以把未落盘的数据页重做回来

1. 执行事务时，先把修改写到 Redo Log buffer，然后再更新到 Buffer Pool
2. 提交事务时，先把 Redo Log buffer 刷盘，再把 Buffer Pool 刷盘（在实际业务中 Buffer Pool 不会立刻刷盘，因为**磁盘随机写的速度很慢**，会严重降低整体性能）

**循环写**：redo log 虽然是一组日志文件，但它的总空间是固定大小的，写满之后不会无限扩展，而是从头覆盖旧的日志，但是在覆盖之前，必须确认旧日志对应的数据已经刷盘，需要保证 **checkpoint 始终先于 write pos**

- **write pos**：表示即将写日志的位置
- **checkpoint**：表示已经持久化到磁盘的位置

```sql
-- 查看 redo log 的单个文件大小
SHOW VARIABLES LIKE 'innodb_log_file_size';

-- 查看 redo log 文件组的数量
SHOW VARIABLES LIKE 'innodb_log_files_in_group';

-- 事务提交时 redo log 的刷盘策略（0 每秒，1 每事务，2 依赖 OS）
SHOW VARIABLES LIKE 'innodb_flush_log_at_trx_commit';

-- 查看 innodb 日志缓冲区大小
SHOW VARIABLES LIKE 'innodb_log_buffer_size';

-- 查看 redo log 相关状态变量
SHOW GLOBAL STATUS LIKE 'Innodb_os_log%';
```

### undo log

undo log 也是 InnoDB 存储引擎独有的日志文件，它记录的是数据修改前的旧值，主要用于事务回滚

- **原子性**：一旦事务失败，可以利用 undo log 回滚到修改前到状态
- **MVCC**：当写事务和读事务同时执行的时候，InnoDB 可以通过 undo log 找到数据修改前的快照提供给读事务，不需要等待写事务执行完毕，从而提高了并发性能

回收写：InnoDB 有一个 **后台 Purge 线程**，会定期扫描 undo log，判断哪些记录已经不再被任何事务使用，然后物理删除这些记录，释放空间或标记为可复用

```sql
-- 查看 undo log 文件数量
SHOW VARIABLES LIKE 'innodb_undo_tablespaces';

-- 查看 undo log 是否支持回收
SHOW VARIABLES LIKE 'innodb_undo_log_truncate';

-- 查看 undo log 路径
SHOW VARIABLES LIKE 'innodb_undo_directory';

-- 查看 undo 日志相关状态
SHOW GLOBAL STATUS LIKE 'Innodb_undo%';
```

### 区别

| 特性     | binlog                                  | redo log                                                     | undo log                                                     |
| -------- | --------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 记录单位 | SQL 语句                                | 物理页修改                                                   | 数据旧值                                                     |
| 记录对象 | 执行器                                  | InnoDB                                                       | InnoDB                                                       |
| 核心功能 | 主从复制                                | 崩溃恢复                                                     | 事务回滚                                                     |
| 存储文件 | 无限追加                                | 循环写                                                       | 回收写                                                       |
| 伪示例   | `UPDATE student SET age=20 WHERE id=1;` | `lsn=123456, space_id=5, page_no=120, offset=0x60, old=18, new=20` | `trx_id=1009, table=student, row_id=1, before image: age=18` |



## 事务

### ACID

- **原子性 Atomicity**：事务是最小的执行单位，不允许分割，事务确保操作要么全部完成，要么全部不完成
- **一致性 Consistency**：事务执行前后，数据要从一个一致性状态转变为另一个一致性状态
- **隔离性 Isolation**：并发事务之间互不干扰，每个事务好像独占数据库运行
- **持久性 Durability**：事务提交后，结果必须持久保存，即使系统崩溃也能恢复

> A、I、D 是手段，C 才是最终目的

### 并发事务问题

**脏读（Dirty Read）**：一个事务读到另一个事务**未提交**的数据，导致**读取数据的内容是错误的**

![image-20250925101724757](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509251017403.png)

**不可重复读（Non-repeatable Read）**：一个事务读到另一个事务**已提交更新**的同一行，导致**前后读取的内容不一致**![image-20250925102216755](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509251022806.png)

**幻读（Phantom Read）**：一个事务读到另一个事务**已提交插入/删除**的同一行，导致**前后读取的结果集行数不一致**

![image-20250925102923218](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509251029293.png)

### 事务隔离级别

| **隔离级别**         | **脏读** | **不可重复读** | **幻读** | 锁对象                         | **说明**                               |
| -------------------- | -------- | -------------- | -------- | ------------------------------ | -------------------------------------- |
| **READ UNCOMMITTED** | ✅        | ✅              | ✅        | 基本不加锁                     | 可以读未提交的数据，性能最高但最不安全 |
| **READ COMMITTED **  | ❌        | ✅              | ✅        | 读加行级共享锁，写加行级排他锁 | 只能读已提交的数据                     |
| **REPEATABLE READ**  | ❌        | ❌              | ✅        | 读用 MVCC 快照，写加行级排他锁 | 性能较好                               |
| **SERIALIZABLE**     | ❌        | ❌              | ❌        | 表级加锁                       | 事务串行化执行，最安全但性能最差       |

> 需要注意的是，MySQL 的 REPEATABLE READ 在写时不仅使用了行级排他锁，还使用了行级间隙锁，因此很大程度上也解决了幻读问题，所以是 MySQL 的默认级别，可以通过 `SELECT @@transaction_isolation;` 查看



## 锁

### 共享锁/排他锁

**共享锁（Shared Lock）**：允许多个事务同时读，但禁止其他事务写

```sql
SELECT ... FOR SHARE;
```

**排他锁（Exclusive Lock）**：只允许上锁的事务读写

```sql
SELECT ... FOR UPDATE;
```

> 行级锁不能手动释放，只能随着事务结束释放

### 表级锁

表级锁是粒度最粗的锁，对整个表上锁会强行阻塞其他事务所有 DML/DDL，但前提是**表中没有行级锁存在，**表锁实现是最简单的，但是并发性能是最低的

```sql
LOCK TABLES my_table READ;
LOCK TABLES my_table WRITE;
UNLOCK TABLES;
```

### 意向锁

意向锁是 InnoDB 存储引擎实现表级锁的一种方式，**用来表明某个事务意图在当前表的某些行上加行锁，从而让当前快速判断是否可以给当前表加表锁**，意向锁由数据引擎维护，用户无法直接操作，意向锁之间是互相兼容的

| 关系 | IS 锁 | IX 锁 |
| ---- | ----- | ----- |
| S 锁 | 兼容  | 互斥  |
| X 锁 | 互斥  | 互斥  |

> 如果行级锁发现不存在索引会自动退回到表级锁

### 行级锁

行级锁是粒度最细的锁，对若干行上锁，但本质上是对索引上锁，并发性能很高，但是会出现死锁问题

| 类型                     | 定义                                                         | 触发               |
| ------------------------ | ------------------------------------------------------------ | ------------------ |
| **记录锁 Record Lock**   | 锁定某一行                                                   | 等值匹配唯一索引   |
| **间隙锁 Gap Lock**      | 锁定某一范围                                                 | 范围查询           |
| **临键锁 Next-key Lock** | 锁定目标记录和其前面的区间（左开右闭），实际上就是记录锁+间隙锁 | 等值匹配非唯一索引 |

> 行级锁只能等待事务结束后自动释放锁

### 自增锁

当表字段里有 AUTO_INCREMENT 属性时，插入新行 InnoDB 引擎会自动分配一个自增值，为了避免并发事务同时插入数据时自增值冲突，可以通过参数 `innodb_autoinc_lock_mode` 控制

| **模式** | **名称**   | **特点**                                                     | **连续性**                 | **性能** |
| -------- | ---------- | ------------------------------------------------------------ | -------------------------- | -------- |
| 0        | 表级锁模式 | 插入语句执行期间，表级 AUTO-INC 锁，逐条分配 ID，整个批次结束才释放锁 | 同个事务内严格连续         | 最差     |
| 1        | 互斥量模式 | 使用轻量级互斥量逐行分配 ID，多个事务交错时可能跳号          | 同个事务内可能跳号         | 较好     |
| 2        | 交错模式   | 每个事务预分配一段 ID，直接用，不保证顺序                    | 分配过多会导致跳号间隙很大 | 最好     |



## MVCC

### 定义

MVCC（Multi-Version Concurrency Control）是 InnoDB 为了实现高并发而引入的一种机制，它可以让读操作和写操作之间不会互相阻塞，通过保存数据的多个版本，让不同事务在同一时刻看到的同一行数据不一样

### 实现机制

- 隐藏字段：每一行数据在 InnoDB 都会额外添加的内容
    - `TRX_ID`：表示最后一次修改该行的事务 ID
    - `ROLL_PTR`：指向 undo log，找到数据的历史版本
- undo log：每次事务更新数据时，都会把旧值写入 undo log
- read view：读视图，用来决定当前事务可以看到哪些版本的数据
    - `m_low_limit_id`：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID，大于等于这个 ID 的数据版本都不可见
    - `m_up_limit_id`：活跃事务列表 `m_ids` 中最小的事务 ID，小于这个 ID 的数据版本都可见
    - `m_ids`：创建该读视图时仍然活跃且没有提交的事务 ID 列表（不包括自己）
    - `m_creator_trx_id`：创建该读视图的事务 ID

### 执行过程

1. 事务 A 开始，生成一个 Read View
2. 事务 A 查询一行数据，如果该行的 `TRX_ID` 小于 Read View 的 `m_up_limit_id`，说明上一个修改该行的事务已经提交，可以直接看到
3. 如果该行的 `TRX_ID` 属于 `m_ids`，说明上一个修改该行的事务还未提交，就需要通过 `ROLL_PTR` 去 undo log 找到旧版数据
4. 在 undo log 之中，每一条日志记录了 `trx_id`、 `ROLL_PTR` 和 `old_val`，如果当前记录的 `trx_id`  小于 `m_up_limit_id`，那么就会返回该 `old_val`
5. 否则，将会继续根据 `ROLL_PTR` 回溯更早之前的历史版本，直到找到可读的数据

> READ COMMITTED 在每次 select 都会生成一个 Read View
>
> REPEATABLE READ 只在当前事务生成一个 Read View，这也是避免不可重复读的最核心原因



## 索引

### 定义

索引是一种**有序的，用于快速查询和检索数据的数据结构**，而不是一个值、一个字段或者一张表，索引需要占用额外的存储空间，而且增删改的时候需要额外开销来维护索引

- **高选择性的列优先**：选择性 = **不同值数量 / 总记录数**，选择性越高，索引过滤效果越好
- **查询频繁的列优先**：指的是 SELECT 的列，这种索引又叫**覆盖索引**，即索引值正好是查询值，不需要回表
- **条件频繁的列优先**：指的是 WHERE、JOIN、ORDER BY、GROUP BY 中的列，可以**避免全表扫描**，快速定位到候选行

### 索引类别

按存储方式分

- **聚簇索引（Clustered Index）**：索引结构和数据一起存放，存完整的行记录
- **辅助索引（Secondary Index）**：索引结构和数据分开存放，只存索引列的值和主键值，完整的数据需要再去聚簇索引中查找

按应用维护划分

- **主键索引**：有唯一约束和非空约束，是聚簇索引，使用 PRIMARY KEY 时自动创建，一个表只能有一个主键索引
- **唯一索引**：有唯一约束但没有非空约束，是辅助索引，使用 UNIQUE 时自动创建
- **列索引**：没有唯一约束和非空约束，是辅助索引，在任何一列上手动创建

### 组合索引

组合索引可以在任何若干列上手动创建，约束和存储方式都取决于组合的列

```sql
CREATE INDEX idx_name ON student(age, name);
```

**最左前缀匹配原则**：组合索引 (a, b, c) 是按 (a → b → c) 排序存储的，也就是说查找时必须 从最左的列开始利用索引，否则无法高效定位

- 如果只看 age：1, 1, 1, 3, 3, 4, 5, 6, 7 是数值有序的
- 如果只看 name：Jason, Mark, Micky, Dasi, David, Alice, Even, Ivy, Bob 是字母无序的 
- 如果相同 age 下再看 name：1【Jason, Mark】, 3【Dasi, David】是字母有序的

![image-20250926094729925](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509260947060.png)

**索引下推（Index Condition Pushdown, ICP**）：只适用于组合辅助索引的范围查找，在根据索引定位候选行时，会直接应用部分 WHERE 过滤条件，而不是提交到 Server 层过滤

```sql
-- 存储引擎直接返回的就是 (1,Mark) 和 (1,Micky)
SELECT * FROM student WHERE age = 1 AND name = 'M%';
```

### 索引方式

| **结构**      | **存储特点**                                                 | 单值查询                     | 范围查询               | **更新性能**  |
| ------------- | ------------------------------------------------------------ | ---------------------------- | ---------------------- | ------------- |
| **Hash 索引** | 通过哈希函数计算存储位置，无顺序性                           | O(1)                         | O(n)                   | 重哈希        |
| **BST**       | 不平衡的二叉树，每个节点左小右大，中序遍历有序               | 平均 O(log n)，最坏 O(n)     | O(n)                   | 破坏平衡      |
| **AVL 树**    | 严格平衡的 BST，左右子树高度差 ≤ 1                           | O(log n)                     | O(log n + k)           | 频繁旋转      |
| **红黑树**    | 弱平衡的 BST，每条路径黑节点数相等，最长路径不会超过最短路径 2 倍 | O(log n)                     | O(log n + k)           | 有限旋转      |
| **B Tree**    | 严格平衡的 m 阶树，节点既存 key 又存 data，数据分布在各层节点 | O(log n)                     | O(log n + k)，中序遍历 | 频繁分裂/合并 |
| **B+Tree**    | 严格平衡的 m 阶树，内部节点只存 key，叶子节点存 key+data，叶子节点之间用链表连接 | 单值查找快，范围查询性能极佳 | O(log n + k)，链表遍历 | 少量分裂/合并 |

![image-20250926091948902](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509260919016.png)

### 索引失效

- 索引字段被包裹在函数里面，或者参与了运算

    ```sql
    SELECT * FROM student WHERE YEAR(birth) = 1990;
    SELECT * FROM student WHERE age + 1 >= 22;
    ```

- 字符串的模糊查询不是前缀匹配，即以 % 开头

    ```sql
    SELECT * FROM student WHERE name LIKE '%dasi';
    ```

- 没有遵循组合索引的最左前缀匹配原则

    ```sql
    CREATE INDEX idx_name_age ON student(name, age);
    SELECT * FROM student WHERE age = 20;
    ```

- 范围过大的查询

    ```sql
    SELECT * FROM student WHERE age > 1;
    SELECT * FROM student WHERE age IN (20, 30, 40);
    ```

- OR 条件混合了非索引列

    ```sql
    SELECT * FROM student WHERE name = 'Tom' OR age = 20;
    ```



## 存储结构

### 表空间

表空间（TableSpace）：可以是 ibdata 文件（所有表存在一起），也可以是 .ibd 文件（一个表对应一个）

1. **段（Segment）**：分为数据段（存叶子节点）、索引段（存内部节点）、回滚段（存 undo log）
2. **区（Extent）**：默认大小是 1MB，InnoDB 会以区为单位分配空间
3. **页（Page）**：默认大小是 16 KB，InnoDB 会以页为单位管理磁盘
4. **行（Row）**：存放一条记录

![image-20250926160032087](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509261600208.png)

### COMPACT 行

- **变长字段长度列表**：可选的，如果当前表有变长字段（VARCHAR、TEXT、BLOB），就会存储当前行所有变长列的实际**字节长度**
- **NULL 位图**：可选的，如果当前表允许有 NULL，就会有一个 bitmap 存储当前行哪些列的值是 NULL
- **记录头**：存放行的元信息
    - **delete_mask**：标记是否被删除，用于延迟删除，交给 purge 线程来实现真正的物理删除
    - **min_rec_flag**：标记当前行是否是某个 B+ 树内部节点的最小记录，用于 B+ 树的边界查找，帮助快速确定范围扫描的起点
    - **n_owned**：页目录中，每个槽指向某一组记录的最后一条，该值表示当前行负责组的记录数，用于页目录的二分查找，提高单页内查找效率
    - **heap_no**：当前行在页中的位置编号
    - **record_type**：记录类型，0 是 B+ 叶子节点，1 是 B+ 树内部节点，2 是最小记录（infimum），3 是最大纪录（supremum）
    - **next_record**：存储下一条记录的偏移量，因为每行的长度不一样，用于快速跳到下一行数据
- **隐藏列**：由 InnoDB 自动为每行数据维护的字段，用户无法改变
    - **row_id**：在表没有定义主键时，InnoDB 会自动生成的隐式自增主键
    - **trx_id**：最后修改该行的事务 ID
    - **roll_ptr**：指向 undo log 的回滚指针，用于找到该行的旧版本
- **数据列**
    - 聚簇索引的叶子节点：存所有列的值
    - 辅助索引的叶子节点：存索引列的值和主键值
    - 内部节点：存索引列的值和子页指针

![image-20250926163603474](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509261636544.png)

### B+ 树结构

在 InnoDB 中，**每个节点都是一个数据页**

![af5a02904fe8568d7119ae25d1b1385a](https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509261649219.png)



## 性能优化

### EXPLAIN

EXPLAIN 展示了 MySQL 通过查询优化器对语句进行分析，找出最优的查询方案，并显示对应的信息

| **字段**          | **含义**                                                     |
| ----------------- | ------------------------------------------------------------ |
| **id**            | 查询的序列标识符，值越大执行优先级越高                       |
| **select_type**   | 查询类型：<br />- SIMPLE 简单查询<br />- PRIMARY 主查询<br />SUBQUERY 来自 WHERE 的子查询<br />- DERIVED 来自 FROM 的子查询<br />- UNION 并集查询 |
| **table**         | 正在访问的表名                                               |
| **partitions**    | 匹配的分区，对于未分区的表值为 NULL                          |
| **type**          | 查询类型，性能从好到差：<br />- system：表只有一行数据<br />- const：使用唯一索引作为查询条件，只返回一条<br />- eq_ref：使用唯一索引作为连接条件，只返回一条<br />- ref：使用普通索引作为查询/连接条件，可能返回多条<br />- index_merge：使用了多个索引组合作为查询条件<br />- range：利用索引的范围查询<br />- index：遍历整个索引树<br />- ALL：全表扫描 |
| **possible_keys** | 可能使用到的索引                                             |
| **key**           | 实际使用到的索引                                             |
| **key_len**       | 索引长度，即列的长度，在满足需求的前提下越短越好             |
| **ref**           | 当使用索引等值查询时，与索引作比较的列或常量                 |
| **rows**          | 预估需要扫描的行数，数值越小越好                             |
| **filtered**      | 经过条件过滤后预计保留的百分比，数值越大越好                 |
| **Extra**         | 额外信息<br />- Using filesort：无法利用索引完成排序，需要额外的排序操作<br />- Using temporary：需要创建临时表来存储查询结果，如 ORDER BY 和 GROUP BY<br />- Using index：使用了覆盖索引<br />- Using Index condition：使用了索引下推<br />- Using where：使用了索引，但还需要额外判断条件 |

### 读写分离

读写分离是**数据库层面的负载均衡方案，将读操作和写操作分散到不同的数据库节点上，从而大幅度提升读性能，防止读操作被写操作阻塞**

- 请求分发：通过 MySQL Router、MyCat 等代理层，将 SQL 请求分发到不同的数据库
- 主从复制：主库负责写，从库负责读，主库和从库之间通过 binlog 进行数据同步
    1. 主库会将数据库中的数据变化写入 binlog
    2. 从库连接到主库后，会创建一个 I/O 线程来请求 binlog
    3. 主库收到请求后，会创建一个 binlog dump 线程来发送 binlog
    4. 从库的 I/O 线程会把接收到的 binlog 写入自己的 relay log
    5. 从库的 SQL 线程会重放 relay log 把数据同步到本地
- 主从延迟：是主从复制不可避免的问题，如果同步延迟过大，会导致主库和从库的数据长期处于不一致状态
    - **半同步复制**：数据库层面，要求主库提交事务时，不仅写本地 redo log + binlog，还会等待至少一个从库确认已经写入 relay log，才向客户端返回成功
    - **强制主库**：代理层面，让关键业务（更新频繁、最新数据）走主库而不走从库
    - **延迟读取**：客户端层面，先检测从库的延迟情况，如果超过阈值，则等待若干秒后再读

<img src="https://dasi-blog.oss-cn-guangzhou.aliyuncs.com/Java/202509261100299.png" alt="image-20250926110033121" style="zoom:50%;" />

### 分库分表

| **方式**     | **拆分规则**   | **示例**                                      | **优点**                                 | **缺点**                     |
| ------------ | -------------- | --------------------------------------------- | ---------------------------------------- | ---------------------------- |
| **垂直分库** | 按业务类型划分 | user_db、order_db、product_db                 | 适合微服务，支持高并发业务，降低单库压力 | 跨库连接复杂                 |
| **水平分库** | 按数据内容划分 | 按 user_id % 4 分到 user_db_0 ~ user_db_3     | 解决单库存储瓶颈                         | 跨库事务复杂                 |
| **垂直分表** | 按列字段拆分   | 热字段作为 user_info，冷字段作为 user_profile | 主表更小，查询更快                       | 查完整信息需要连接           |
| **水平分表** | 按行数据划分   | 按年月分为 order_202401、order_202402         | 避免单表过大，增加查询、索引、写入性能   | 跨表查询麻烦；分表规则要慎重 |

### 分片

分片就是**按照某个分片键，根据某种分片算法，把一张表的数据拆分到多个物理节点中**，每个分片存相同的表结构，但数据不一样，而分片性能很大程度上取决于分片键的选择

- **覆盖**：大多数查询语句的 WHERE 条件中最好包含分片键
- **稳定**：分片键的值不应频繁修改，否则数据需要频繁迁移
- **离散**：分片键的取值要足够分散，能把数据均匀打散到各个分片
- **扩展**：当数据量继续增长时，能通过增加分片数量轻松扩展

| **分片算法**       | **规则**                                           | **优点**               | **缺点**                       |
| ------------------ | -------------------------------------------------- | ---------------------- | ------------------------------ |
| **哈希分片**       | 对分片键进行取模运算                               | 均匀分布，避免热点     | 扩容需迁移大量数据             |
| **范围分片**       | 按范围区间划分                                     | 范围查询高效           | 热点集中在一个范围             |
| **一致性哈希分片** | 将分片键和节点都映射到这个环上，按顺时针找最近节点 | 扩容缩容只迁移少量数据 | 实现复杂，需要虚拟节点         |
| **映射表分片**     | 单独用一个路由表存储 key → 库/表的映射关系         | 灵活，扩容/迁移方便    | 需要额外存储空间，单点故障风险 |



## SQL 优化

### 避免使用 SELECT *

- 影响性能：SELECT * 会把所有的列都取出来，即使应用层可能只用到部分数据，会增加网络、CPU 和 I/O 开销
- 干扰索引：SELECT * 让优化器无法利用覆盖索引
- 避免出错：如果表结构和对象结构存在不一致，只获取部分列可以有效避免兼容性问题

### 避免使用外键、级联、连接

在高并发实际业务中，会将外键获取数据，级联更新/删除，多表连接都交给应用层代码来做，这是因为**应用层在内存处理数据，会比数据库处理数据快得多，宁愿选择多次单表查询也不要多表单次查询**

- 外键约束和级联操作会让数据库在插入、更新、删除时额外做完整性校验，增加锁竞争和性能开销，尤其在高并发下拖慢整体效率
- 在分库分表、分布式场景下，外键几乎无法跨库维护一致性，限制了架构扩展能力
- 外键和级联的逻辑是“写死”的，灵活性差，不利于业务上更复杂的数据一致性策略（如部分保留、归档、逻辑删除）
- JOIN 查询需要数据库在执行时做大量的关联计算，当数据量大时非常消耗 CPU 和内存，容易成为性能瓶颈
- 在分库分表和分布式架构下跨库 JOIN 完全不可用

> 还有包括用 UNION ALL 而不是 UNION 等原因，都是希望**把数据处理的任务交给应用层来解决，数据库只负责存和取**

### 深度分页优化

MySQL 的分页查询实际上并不是分好页后获取指定页，而是顺序获取到 offset + size 条数据，然后抛弃前面的 offset 条，只返回一页的 size 条，所以查询深度越深，offset 越大，无用的查找就越多，性能就越拉跨

```sql
SELECT name, age
FROM student 
ORDER BY id
LIMIT 1000000, 10;
```

实际上可以利用**主键覆盖索引，先快速获取 id，而不是更大的 name 和 age，然后取主键作为查询/连接条件取 size 条，极大程度减少了 I/O 开销**，但是子查询的结果会新产生一张临时表，还是会损耗一定性能

```sql
SELECT name, age 
FROM student
WHERE id >= (
  	SELECT id 
  	FROM student 
  	ORDER BY id
  	LIMIT 1000000, 1
)
LIMIT 10;

SELECT name, age
FROM student a
INNER JOIN (
		SELECT id
  	FROM student
  	LIMIT 1000000, 10
) b
ON a.id = b.id
LIMIT 10;
```